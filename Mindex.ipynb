{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#we want to hide the keys so they aren't made public on github, python-dotenv will allow us to do this\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "#create variables for the csv files to be stored in, as well as a variable bucket to store the name of \n",
    "#the bucket on Mindex AWS Server\n",
    "\n",
    "bucket = mindex-data-analytics-code-challenge\n",
    "file_name1 = bengals.csv\n",
    "file_name2 = boyd_receiving.csv\n",
    "file_name3 = chase_receiving.csv\n",
    "file_name4 = higgins_receiving.csv\n",
    "\n",
    "# 's3' is a key word. create connection to S3 using default config and all buckets within S3\n",
    "#establish client connection to Mindex AWS Server using their keys which we hide with .env.\n",
    "#.env. is stored in .gitignore. so they don't accidentally get published to github\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=SECRET_ACCESS_KEY\n",
    "    #aws_session_token=SESSION_TOKEN #this one is optional, so not needed here\n",
    ")\n",
    "\n",
    "obj1 = s3.get_object(Bucket= bucket, Key= file_name1) \n",
    "obj2 = s3.get_object(Bucket= bucket, Key= file_name2) \n",
    "obj3 = s3.get_object(Bucket= bucket, Key= file_name3) \n",
    "obj4 = s3.get_object(Bucket= bucket, Key= file_name4) \n",
    "# get object and file (key) from bucket\n",
    "\n",
    "df1 = pd.read_csv(obj1['Body']) # 'Body' is a key word\n",
    "df2 = pd.read_csv(obj2['Body']) # 'Body' is a key word\n",
    "df3 = pd.read_csv(obj3['Body']) # 'Body' is a key word\n",
    "df4 = pd.read_csv(obj4['Body']) # 'Body' is a key word\n",
    "\n",
    "df2.rename(columns={\"Week\":\"Week\", \"Yards\":\"Boyd_Yards\", \"TD\":\"Boyd_TD\"}, inplace=True)\n",
    "df3.rename(columns={\"Week\":\"Week\", \"Yards\":\"Chase_Yards\", \"TD\":\"Chase_TD\"}, inplace=True)\n",
    "df4.rename(columns={\"Week\":\"Week\", \"Yards\":\"Higgins_Yards\", \"TD\":\"Higgins_TD\"}, inplace=True)\n",
    "\n",
    "df_merged = pd.merge(df1, df2, left_on=['Week'],\n",
    "              right_on=['Week'],\n",
    "              how='left')\n",
    "\n",
    "df_merged = pd.merge(df_merged, df3, left_on=['Week'],\n",
    "              right_on=['Week'],\n",
    "              how='left')\n",
    "\n",
    "df_merged = pd.merge(df_merged, df4, left_on=['Week'],\n",
    "              right_on=['Week'],\n",
    "              how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
